{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffad27f-5e92-45b3-8a67-528da7d65237",
   "metadata": {},
   "source": [
    "# Between Resolution Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d97fa6d7-9971-46e4-998e-dfbdd5e7997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import cosima_cookbook as cc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "xr.set_options(keep_attrs=True)\n",
    "\n",
    "import cf_xarray as cfxr\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "import xesmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "170a0539-addb-4f57-8c99-5dd2c62cbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting a dask client\n",
    "from os import environ\n",
    "environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c8b1a-da02-4ccf-9211-74f1a924827a",
   "metadata": {},
   "source": [
    "A function that loads the diagnostics needed (independently of the model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30807f9b-66d7-42da-b0ce-edcc5b24b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables(expt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom5'):\n",
    "\n",
    "    # The models require different diagnostics to calculate the heat and salt fluxes.\n",
    "    # mom6 outputs a net flux, whilst with mom5 we need to work with the separate components.\n",
    "    model_vars = {\n",
    "                    \"mom5\": {\n",
    "                        \"temperature\":           [\"temp\"],\n",
    "                        \"salinity\":              [\"salt\"],\n",
    "                        \"water_flux_into_ocean\": [\"pme_net\"],\n",
    "                        \"salt_flux\":             [\"sfc_salt_flux_ice\", \"sfc_salt_flux_restore\"],\n",
    "                        \"heat_flux\":             [\"sfc_hflux_coupler\", \"sfc_hflux_from_runoff\",\n",
    "                                                  \"frazil_3d_int_z\", \"sfc_hflux_pme\"],\n",
    "                        \"area\":                  [\"area_t\"],\n",
    "                        \"maximum_depth\":         [\"ht\"],\n",
    "                    },\n",
    "                    \"mom6\": {\n",
    "                        \"temperature\":           [\"thetao\"],\n",
    "                        \"salinity\":              [\"so\"],\n",
    "                        \"water_flux_into_ocean\": [\"wfo\"],\n",
    "                        \"salt_flux\":             [\"salt_flux\"],\n",
    "                        \"heat_flux\":             [\"hfds\"],\n",
    "                        \"area\":                  [\"areacello\"],\n",
    "                        \"maximum_depth\":         [\"deptho\"],\n",
    "                    }\n",
    "                }\n",
    "    # Load variables in a dictionary\n",
    "    ds = {}\n",
    "    keys = list(model_vars[model].keys())\n",
    "    for k in keys:\n",
    "        ds[k] = {}\n",
    "        for var in model_vars[model][k]:\n",
    "            if k in [\"area\", \"maximum_depth\"]:\n",
    "                ds[k][var] = cc.querying.getvar(expt, var, session, n = 1) \n",
    "                ds[k][var] = ds[k][var].cf.sel(X = lon_slice, Y = lat_slice)\n",
    "            else:\n",
    "                ds[k][var] = cc.querying.getvar(expt, var, session,\n",
    "                                                frequency = freq,\n",
    "                                                start_time = start_time,\n",
    "                                                end_time = end_time,\n",
    "                                                chunks = {'time': 'auto'})\n",
    "                ds[k][var] = ds[k][var].cf.sel(X = lon_slice, Y = lat_slice, time = slice(start_time, end_time))\n",
    "                \n",
    "                # Correct temperatures (if in K convert to C)\n",
    "                if k == 'temperature' and np.max(ds[k][var]) > 100:\n",
    "                    ds[k][var] = ds[k][var] - 273.15\n",
    "\n",
    "                # If 3D field, grab the surface\n",
    "                if ds[k][var].cf.axes.get('Z'):\n",
    "                    surface_z = ds[k][var].cf['Z'][0].values\n",
    "                    ds[k][var] = ds[k][var].cf.sel(Z = 0, method = 'nearest')\n",
    "\n",
    "    # Get temperature and salinity to calculate a couple other things we'll need later on\n",
    "    CT = ds['temperature'][model_vars[model]['temperature'][0]]\n",
    "    SP = ds['salinity'][model_vars[model]['salinity'][0]]\n",
    "\n",
    "    # Calculate pressure\n",
    "    pressure = gsw.p_from_z(-surface_z, SP.cf['Y']).rename('pressure')\n",
    "\n",
    "    # Calculate absolute salinity\n",
    "    SA = gsw.SA_from_SP(SP, pressure, SP.cf['X'], SP.cf['Y']).rename('SA')\n",
    "\n",
    "    # Calculate potential density\n",
    "    pot_rho_1 = gsw.sigma1(SA, CT).rename('pot_rho_11')\n",
    "\n",
    "    # Save everything to our dictionary\n",
    "    ds['pressure'] = pressure\n",
    "    ds['SA'] = SA\n",
    "    ds['pot_rho_1'] = pot_rho_1\n",
    "    \n",
    "    # Calculate days per month accounting for leap years\n",
    "    months_standard_noleap = np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "    months_standard_leap = np.array([31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "    if 'ryf' or 'panan' in expt:\n",
    "        nyears = len(np.unique(CT['time.year']))\n",
    "        days_per_month = np.tile(months_standard_noleap, nyears)\n",
    "    elif 'iaf' in expt:\n",
    "        nyears = len(np.unique(CT['time.year']))\n",
    "        if CT['time.year'][0] % 4 == 0:\n",
    "            days_per_month = months_standard_leap\n",
    "        else: \n",
    "            days_per_month = months_standard_noleap\n",
    "        for yr in CT['time.year'][::12][1:]:\n",
    "            if yr % 4 == 0:\n",
    "                days_per_month = np.concatenate([days_per_month, months_standard_leap])\n",
    "            else:\n",
    "                days_per_month = np.concatenate([days_per_month, months_standard_noleap])\n",
    "    days_per_month = xr.DataArray(days_per_month, dims = ['time'], coords = {'time': CT['time']}, name = 'days_per_month')\n",
    "    ds['days_per_month'] = days_per_month\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c29f0758-f67d-4437-b7e7-932734f1606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading database\n",
    "\n",
    "pan01control = 'panant-01-zstar-ACCESSyr2'\n",
    "db = '/home/272/kc5856/local_cc_test.db'\n",
    "session = cc.database.create_session(db)\n",
    "\n",
    "freq = '1 monthly'\n",
    "\n",
    "# Select time period and region\n",
    "start_time = '2007-01-01'\n",
    "end_time = '2010-12-31'\n",
    "lon_slice = slice(None, None)\n",
    "lat_slice = slice(None, -59)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4bc933-554a-4d45-950f-fb79e98c06a4",
   "metadata": {},
   "source": [
    "Next we load the grid parameters for each resolution. We use .reset_coords(), .drop() and .rename() on some grids to make them compatible with the xesmf package requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf8806-7c1c-4114-8df0-af8e28fd44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Panan01\n",
    "\n",
    "ocean_static_01 = xr.open_dataset('/g/data/ik11/outputs/mom6-panan/panant-01-zstar-ACCESSyr2/output021/20000701.ocean_static.nc')\n",
    "grid_010 = xgcm.Grid(ocean_static_01, coords = {'X': {'center': 'xh', 'right': 'xq'},\n",
    "                                     'Y': {'center': 'yh', 'right': 'yq'}},\n",
    "                                   periodic = ['X'])\n",
    "\n",
    "#Panan005\n",
    "\n",
    "ocean_static_005_MW = xr.open_dataset('/g/data/g40/akm157/model_output/mom6-panan/panant-005-zstar-ssp126-MW-only/output120/20010101.ocean_static.nc')\n",
    "grid_005 = xgcm.Grid(ocean_static_005_MW, coords = {'X': {'center': 'xh', 'right': 'xq'},\n",
    "                                     'Y': {'center': 'yh', 'right': 'yq'}},\n",
    "                                   periodic = ['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb59bcd-9257-42ac-a7b8-8013118c5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_variables(pan01control, freq, start_time, end_time, lon_slice, lat_slice, model = \"mom6\").to_dask()\n",
    "\n",
    "ssh_1 = (ds[\"sea_level\"].sel(time=slice(\"2001-01-01\", \"2010-12-31\")).cf.chunk({\"time\": \"auto\", \"longitude\": -1, \"latitude\": -1}))\n",
    "ssh_1 = ssh_1.assign_coords({\"geolat_t\": grid1.geolat_t, \"geolon_t\": grid1.geolon_t})\n",
    "ssh_1 = ssh_1.rename({\"xt_ocean\": \"x\", \"yt_ocean\": \"y\"})\n",
    "ssh_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d30f7-18f8-4b51-aeac-7956986762bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-24.04] *",
   "language": "python",
   "name": "conda-env-analysis3-24.04-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
