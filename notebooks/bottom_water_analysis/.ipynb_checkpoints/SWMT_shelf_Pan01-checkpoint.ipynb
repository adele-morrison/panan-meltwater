{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fca44b-e35b-44f8-80fc-e8cfce8407e9",
   "metadata": {},
   "source": [
    "# SWMT on shelf for PanAntarctic 1/10th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5734cd-4856-4134-aca5-13269b298462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cf_xarray as cfxr\n",
    "import cmocean as cm\n",
    "import dask.distributed\n",
    "import gsw\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec \n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pdb\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import intake\n",
    "cat = intake.cat.access_nri\n",
    "\n",
    "import warnings # ignore these warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0362bbd5-ee91-4d62-8168-80203de4a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting a dask client\n",
    "from os import environ\n",
    "environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(threads_per_worker = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814c4dee-d7ca-45c7-931c-3d59f27de0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables(expt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom5'):\n",
    "\n",
    "    # The models require different diagnostics to calculate the heat and salt fluxes.\n",
    "    # mom6 outputs a net flux, whilst with mom5 we need to work with the separate components.\n",
    "    model_vars = {\n",
    "                    \"mom5\": {\n",
    "                        \"temperature\":           [\"temp\"],\n",
    "                        \"salinity\":              [\"salt\"],\n",
    "                        \"water_flux_into_ocean\": [\"pme_river\"],\n",
    "                        \"salt_flux\":             [\"sfc_salt_flux_ice\", \"sfc_salt_flux_restore\"],\n",
    "                        \"heat_flux\":             [\"sfc_hflux_coupler\", \"sfc_hflux_from_runoff\",\n",
    "                                                  \"frazil_3d_int_z\", \"sfc_hflux_pme\"],\n",
    "                        \"area\":                  [\"area_t\"],\n",
    "                        \"maximum_depth\":         [\"ht\"],\n",
    "                    },\n",
    "                    \"mom6\": {\n",
    "                        \"temperature\":           [\"thetao\"],\n",
    "                        \"salinity\":              [\"so\"],\n",
    "                        \"water_flux_into_ocean\": [\"wfo\"],\n",
    "                        \"salt_flux\":             [\"salt_flux\"],\n",
    "                        \"heat_flux\":             [\"hfds\"],\n",
    "                        \"area\":                  [\"areacello\"],\n",
    "                        \"maximum_depth\":         [\"deptho\"],\n",
    "                    }\n",
    "                }\n",
    "    # Load variables in a dictionary\n",
    "    ds = {}\n",
    "    keys = list(model_vars[model].keys())\n",
    "    for k in keys:\n",
    "        ds[k] = {}\n",
    "        for var in model_vars[model][k]:\n",
    "            if k in [\"area\", \"maximum_depth\"]:\n",
    "                ds[k][var] = cat[expt].search(variable=var).to_dask(xarray_open_kwargs={\n",
    "                    \"decode_timedelta\": False\n",
    "                })[var]\n",
    "                ds[k][var] = ds[k][var].cf.sel(X = lon_slice, Y = lat_slice)\n",
    "            else:\n",
    "                try:\n",
    "                    ds[k][var] = cat[expt].search(variable=var, frequency=freq).to_dask(\n",
    "                        xarray_open_kwargs={\n",
    "                            \"chunks\": {\"time\": \"auto\"}, \n",
    "                            \"decode_timedelta\": False\n",
    "                        })[var]\n",
    "                    ds[k][var] = ds[k][var].cf.sel(\n",
    "                        X = lon_slice, Y = lat_slice, \n",
    "                        time = slice(start_time, end_time))\n",
    "                    \n",
    "                    # Correct temperatures (if in K convert to C)\n",
    "                    if k == 'temperature' and np.max(ds[k][var]) > 100:\n",
    "                        ds[k][var] = ds[k][var] - 273.15\n",
    "    \n",
    "                    # If 3D field, grab the surface\n",
    "                    if ds[k][var].cf.axes.get('Z'):\n",
    "                        surface_z = ds[k][var].cf['Z'][0].values\n",
    "                        ds[k][var] = ds[k][var].cf.sel(Z = 0, method = 'nearest')\n",
    "                except Exception as e:\n",
    "                    raise Exception(f\"Data loading error: var={var}, freq={freq}, start_time={start_time}, end_time={end_time}, expt={expt}: {str(e)}\")\n",
    "\n",
    "    # Get temperature and salinity to calculate few other things we'll need later on\n",
    "    SP = ds['salinity'][model_vars[model]['salinity'][0]]\n",
    "    CT = ds['temperature'][model_vars[model]['temperature'][0]]\n",
    "\n",
    "    # Calculate pressure\n",
    "    pressure = gsw.p_from_z(-surface_z, SP.cf['Y']).rename('pressure')\n",
    "\n",
    "    # Calculate absolute salinity\n",
    "    SA = gsw.SA_from_SP(SP, pressure, SP.cf['X'], SP.cf['Y']).rename('SA')\n",
    "\n",
    "    # Ensure we have conservative temperature; Convert MOM6's potential temperature to conservative\n",
    "    if model == 'mom6':\n",
    "        CT = gsw.CT_from_pt(SA, CT)\n",
    "        ds['temperature'][model_vars[model]['temperature'][0]].data = CT.values\n",
    "\n",
    "    # Calculate potential density\n",
    "    pot_rho_1 = gsw.sigma1(SA, CT)#.rename('pot_rho_11')\n",
    "\n",
    "    # Save everything to our dictionary\n",
    "    ds['pressure'] = pressure\n",
    "    ds['SA'] = SA\n",
    "    ds['pot_rho_1'] = pot_rho_1\n",
    "    \n",
    "    # Calculate days per month accounting for leap years\n",
    "    months_standard_noleap = np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "    months_standard_leap = np.array([31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "    if 'ryf' or 'panan' in expt:\n",
    "        nyears = len(np.unique(CT['time.year']))\n",
    "        days_per_month = np.tile(months_standard_noleap, nyears)\n",
    "    elif 'iaf' in expt:\n",
    "        nyears = len(np.unique(CT['time.year']))\n",
    "        if CT['time.year'][0] % 4 == 0:\n",
    "            days_per_month = months_standard_leap\n",
    "        else: \n",
    "            days_per_month = months_standard_noleap\n",
    "        for yr in CT['time.year'][::12][1:]:\n",
    "            if yr % 4 == 0:\n",
    "                days_per_month = np.concatenate([days_per_month, months_standard_leap])\n",
    "            else:\n",
    "                days_per_month = np.concatenate([days_per_month, months_standard_noleap])\n",
    "    days_per_month = xr.DataArray(days_per_month, dims = ['time'], coords = {'time': CT['time']}, name = 'days_per_month')\n",
    "    ds['days_per_month'] = days_per_month\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62958e21-8a7b-4b20-8314-9731eb5b6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_salt_transformation(ds):\n",
    "    \n",
    "    # First retrieve temperature and water_flux as an xarray instead of a dictionary\n",
    "    CT = xr.Dataset(ds['temperature']).to_array().squeeze().drop_vars('variable')\n",
    "\n",
    "    # Multiply the water flux by absolute salinity to get it in the correct units\n",
    "    water_flux_into_ocean = xr.Dataset(ds['water_flux_into_ocean']).to_array().squeeze().drop_vars('variable')\n",
    "    water_flux_into_ocean = ds['SA'] * water_flux_into_ocean\n",
    "\n",
    "    # Caculate the haline contraction coefficient\n",
    "    haline_contraction = gsw.beta(ds['SA'], CT, ds['pressure']).rename('beta')\n",
    "\n",
    "    # Calculate the net salt flux and multiply by 1000 to convert units\n",
    "    net_salt_flux = xr.Dataset(ds['salt_flux']).to_array().sum(dim = 'variable') * 1000\n",
    "\n",
    "    # Note that we also multiply pme_river by absolute salinity to have the correct units\n",
    "    salt_transformation = haline_contraction * (water_flux_into_ocean - net_salt_flux) * ds['days_per_month']\n",
    "    salt_transformation = salt_transformation.load()\n",
    "\n",
    "    return salt_transformation\n",
    "\n",
    "def compute_heat_transformation(ds):\n",
    "\n",
    "    # First retrieve temperature as an xarray instead of a dictionary\n",
    "    CT = xr.Dataset(ds['temperature']).to_array().squeeze().drop_vars('variable')\n",
    "\n",
    "    # Calculate the thermal expansion coefficient \n",
    "    thermal_expansion = gsw.alpha(ds['SA'], CT, ds['pressure']).rename('alpha')\n",
    "    \n",
    "    # Calculate the net surface heating\n",
    "    net_surface_heating = xr.Dataset(ds['heat_flux']).to_array().sum(dim = 'variable')\n",
    "    \n",
    "    # Calculate the heat transformation\n",
    "    heat_transformation = thermal_expansion * net_surface_heating * ds['days_per_month']\n",
    "    heat_transformation = heat_transformation.load()\n",
    "\n",
    "    return heat_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14dee8de-8579-4558-89d1-cfe8f5342da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isopycnal_bins(ds, salt_transformation, heat_transformation):\n",
    "\n",
    "    # Next section does a few things. It cycles through isopycnal bins, determines which cells are \n",
    "    # within the given bin for each month, finds the transformation values for those cells for each month, \n",
    "    # and sums these through time. You are left with an array of shape (isopyncal bins * lats * lons) \n",
    "    # where the array associated with a given isopycnal bin is NaN everywhere except where pot_rho_1 \n",
    "    # was within the bin, there it has a time summed transformation value.\n",
    "    \n",
    "    # Choose appropriate bin range\n",
    "    isopycnal_bins = np.arange(31, 33.5, 0.02)  # 125 bins - 31, 33.5, 0.02 (sigma1)\n",
    "    #isopycnal_bins = np.concatenate([np.arange(25.0, 26.5, 0.05), np.arange(26.5, 28.5, 0.02)])  # 130 bins (sigma0)\n",
    "    bin_bottoms = isopycnal_bins[:-1]\n",
    "    isopycnal_bin_mid = (isopycnal_bins[1:] + bin_bottoms) / 2\n",
    "    isopycnal_bin_diff = np.diff(isopycnal_bins)\n",
    "\n",
    "    pot_rho_1 = ds['pot_rho_1']\n",
    "\n",
    "    results_salt = []\n",
    "    results_heat = []\n",
    "\n",
    "    for i in range(len(bin_bottoms)):\n",
    "        # Create binary mask for each bin\n",
    "        bin_mask = xr.where((pot_rho_1 > bin_bottoms[i]) & (pot_rho_1 <= isopycnal_bins[i + 1]), 1, np.nan)\n",
    "\n",
    "        # Multiply and sum over time\n",
    "        salt_sum = (salt_transformation * bin_mask).sum(dim='time')\n",
    "        heat_sum = (heat_transformation * bin_mask).sum(dim='time')\n",
    "\n",
    "        results_salt.append(salt_sum.expand_dims({'isopycnal_bins': [isopycnal_bin_mid[i]]}))\n",
    "        results_heat.append(heat_sum.expand_dims({'isopycnal_bins': [isopycnal_bin_mid[i]]}))\n",
    "\n",
    "    # Concatenate results along isopycnal dimension\n",
    "    salt_transformation = xr.concat(results_salt, dim='isopycnal_bins')\n",
    "    heat_transformation = xr.concat(results_heat, dim='isopycnal_bins')\n",
    "\n",
    "    # Normalise by number of days and bin thickness\n",
    "    ndays = ds['days_per_month'].sum()\n",
    "    c_p = 3992.1 # J kg-1 degC-1\n",
    "\n",
    "    salt_transformation /= ndays\n",
    "    heat_transformation /= (c_p * ndays)\n",
    "\n",
    "    salt_transformation /= isopycnal_bin_diff[:, np.newaxis, np.newaxis]\n",
    "    heat_transformation /= isopycnal_bin_diff[:, np.newaxis, np.newaxis]\n",
    "\n",
    "    # Overwrite zeros with NANs \n",
    "    # (Note: the code within the for-loop should provide nans but lazy computing with dask can sometimes give unpredictable results)\n",
    "    salt_transformation = salt_transformation.where(salt_transformation != 0)\n",
    "    heat_transformation = heat_transformation.where(heat_transformation != 0)\n",
    "\n",
    "    # Change the sign so that positive means conversion into denser water masses\n",
    "    salt_transformation *= -1\n",
    "    heat_transformation *= -1\n",
    "\n",
    "    # Renaming\n",
    "    salt_transformation.name = \"salt_transformation\"\n",
    "    heat_transformation.name = \"heat_transformation\"\n",
    "\n",
    "    return salt_transformation.load(), heat_transformation.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf4858-6c01-4d3d-9d16-c8fd3e42748d",
   "metadata": {},
   "source": [
    "## Saving per year via manual method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02f94c-e53e-4a9c-9d36-ed9eea315bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-25.06] *",
   "language": "python",
   "name": "conda-env-analysis3-25.06-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
