{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f7d039-a80a-4852-a8fa-8c246bd23776",
   "metadata": {},
   "source": [
    "# Pan005 SWMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b1ede-a77b-4197-a4bd-44ad41d67675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import cosima_cookbook as cc\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cf_xarray as cfxr\n",
    "import cmocean as cm\n",
    "import dask.distributed as dsk\n",
    "import gsw\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec \n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import warnings # ignore these warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771c8b1-2768-4c7f-aa0d-581cc98b5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting a dask client\n",
    "from os import environ\n",
    "environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(threads_per_worker = 1)\n",
    "client.amm.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b30e47e-8236-4f88-9638-8efa59e70019",
   "metadata": {},
   "source": [
    "### Computing surface water mass transformation\n",
    "\n",
    "We will do this by defining three functions. The first one loads the diagnostics needed (independently of the model). The second one actually calculates the transformations, and a third one does the density binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a8533-a2b5-4454-8993-4453f6f26062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables(expt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom5'):\n",
    "\n",
    "    # The models require different diagnostics to calculate the heat and salt fluxes.\n",
    "    # mom6 outputs a net flux, whilst with mom5 we need to work with the separate components.\n",
    "    model_vars = {\n",
    "                    \"mom5\": {\n",
    "                        \"temperature\":           [\"temp\"],\n",
    "                        \"salinity\":              [\"salt\"],\n",
    "                        \"water_flux_into_ocean\": [\"pme_net\"],\n",
    "                        \"salt_flux\":             [\"sfc_salt_flux_ice\", \"sfc_salt_flux_restore\"],\n",
    "                        \"heat_flux\":             [\"sfc_hflux_coupler\", \"sfc_hflux_from_runoff\",\n",
    "                                                  \"frazil_3d_int_z\", \"sfc_hflux_pme\"],\n",
    "                        \"area\":                  [\"area_t\"],\n",
    "                        \"maximum_depth\":         [\"ht\"],\n",
    "                    },\n",
    "                    \"mom6\": {\n",
    "                        \"temperature\":           [\"thetao\"],\n",
    "                        \"salinity\":              [\"so\"],\n",
    "                        \"water_flux_into_ocean\": [\"wfo\"],\n",
    "                        \"salt_flux\":             [\"salt_flux\"],\n",
    "                        \"heat_flux\":             [\"hfds\"],\n",
    "                        \"area\":                  [\"areacello\"],\n",
    "                        \"maximum_depth\":         [\"deptho\"],\n",
    "                    }\n",
    "                }\n",
    "    # Load variables in a dictionary\n",
    "    ds = {}\n",
    "    keys = list(model_vars[model].keys())\n",
    "    for k in keys:\n",
    "        ds[k] = {}\n",
    "        for var in model_vars[model][k]:\n",
    "            if k in [\"area\", \"maximum_depth\"]:\n",
    "                ds[k][var] = cc.querying.getvar(expt, var, session, n = 1) \n",
    "                ds[k][var] = ds[k][var].cf.sel(X = lon_slice, Y = lat_slice)\n",
    "            else:\n",
    "                ds[k][var] = cc.querying.getvar(expt, var, session,\n",
    "                                                frequency = freq,\n",
    "                                                start_time = start_time,\n",
    "                                                end_time = end_time,\n",
    "                                                chunks = {'time': 'auto'})\n",
    "                ds[k][var] = ds[k][var].cf.sel(X = lon_slice, Y = lat_slice, time = slice(start_time, end_time))\n",
    "                \n",
    "                # Correct temperatures (if in K convert to C)\n",
    "                if k == 'temperature' and np.max(ds[k][var]) > 100:\n",
    "                    ds[k][var] = ds[k][var] - 273.15\n",
    "\n",
    "                # If 3D field, grab the surface\n",
    "                if ds[k][var].cf.axes.get('Z'):\n",
    "                    surface_z = ds[k][var].cf['Z'][0].values\n",
    "                    ds[k][var] = ds[k][var].cf.sel(Z = 0, method = 'nearest')\n",
    "\n",
    "    # Get temperature and salinity to calculate a couple other things we'll need later on\n",
    "    CT = ds['temperature'][model_vars[model]['temperature'][0]]\n",
    "    SP = ds['salinity'][model_vars[model]['salinity'][0]]\n",
    "\n",
    "    # Calculate pressure\n",
    "    pressure = gsw.p_from_z(-surface_z, SP.cf['Y']).rename('pressure')\n",
    "\n",
    "    # Calculate absolute salinity\n",
    "    SA = gsw.SA_from_SP(SP, pressure, SP.cf['X'], SP.cf['Y']).rename('SA')\n",
    "\n",
    "    # Calculate potential density\n",
    "    pot_rho_1 = gsw.sigma1(SA, CT).rename('pot_rho_11')\n",
    "\n",
    "    # Save everything to our dictionary\n",
    "    ds['pressure'] = pressure\n",
    "    ds['SA'] = SA\n",
    "    ds['pot_rho_1'] = pot_rho_1\n",
    "    \n",
    "    # Calculate days per month accounting for leap years\n",
    "    months_standard_noleap = np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "    months_standard_leap = np.array([31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "    if 'ryf' or 'panan' in expt:\n",
    "        nyears = len(np.unique(CT['time.year']))\n",
    "        days_per_month = np.tile(months_standard_noleap, nyears)\n",
    "    elif 'iaf' in expt:\n",
    "        nyears = len(np.unique(CT['time.year']))\n",
    "        if CT['time.year'][0] % 4 == 0:\n",
    "            days_per_month = months_standard_leap\n",
    "        else: \n",
    "            days_per_month = months_standard_noleap\n",
    "        for yr in CT['time.year'][::12][1:]:\n",
    "            if yr % 4 == 0:\n",
    "                days_per_month = np.concatenate([days_per_month, months_standard_leap])\n",
    "            else:\n",
    "                days_per_month = np.concatenate([days_per_month, months_standard_noleap])\n",
    "    days_per_month = xr.DataArray(days_per_month, dims = ['time'], coords = {'time': CT['time']}, name = 'days_per_month')\n",
    "    ds['days_per_month'] = days_per_month\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6cb919-ad95-4828-ac74-1f1231c83b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_salt_transformation(ds):\n",
    "    \n",
    "    # First retrieve temperature and water_flux as an xarray instead of a dictionary\n",
    "    CT = xr.Dataset(ds['temperature']).to_array().squeeze().drop_vars('variable')\n",
    "\n",
    "    # Multiply the water flux by absolute salinity to get it in the correct units\n",
    "    water_flux_into_ocean = xr.Dataset(ds['water_flux_into_ocean']).to_array().squeeze().drop_vars('variable')\n",
    "    water_flux_into_ocean = ds['SA'] * water_flux_into_ocean\n",
    "\n",
    "    # Caculate the haline contraction coefficient\n",
    "    haline_contraction = gsw.beta(ds['SA'], CT, ds['pressure']).rename('beta')\n",
    "\n",
    "    # Calculate the net salt flux and multiply by 1000 to convert units\n",
    "    net_salt_flux = xr.Dataset(ds['salt_flux']).to_array().sum(dim = 'variable') * 1000\n",
    "\n",
    "    # Note that we also multiply pme_net by absolute salinity to have the correct units\n",
    "    salt_transformation = haline_contraction * (water_flux_into_ocean - net_salt_flux) * ds['days_per_month']\n",
    "    salt_transformation = salt_transformation.load()\n",
    "\n",
    "    return salt_transformation\n",
    "\n",
    "def compute_heat_transformation(ds):\n",
    "\n",
    "    # First retrieve temperature as an xarray instead of a dictionary\n",
    "    CT = xr.Dataset(ds['temperature']).to_array().squeeze().drop_vars('variable')\n",
    "\n",
    "    # Calculate the thermal expansion coefficient \n",
    "    thermal_expansion = gsw.alpha(ds['SA'], CT, ds['pressure']).rename('alpha')\n",
    "    \n",
    "    # Calculate the net surface heating\n",
    "    net_surface_heating = xr.Dataset(ds['heat_flux']).to_array().sum(dim = 'variable')\n",
    "    \n",
    "    # Calculate the heat transformation\n",
    "    heat_transformation = thermal_expansion * net_surface_heating * ds['days_per_month']\n",
    "    heat_transformation = heat_transformation.load()\n",
    "\n",
    "    return heat_transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319286c-0ea3-41c3-a19a-50d5663d1972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isopycnal_bins(ds, salt_transformation, heat_transformation):\n",
    "    \n",
    "    # Next section does a few things. It cycles through isopycnal bins, determines which cells are \n",
    "    # within the given bin for each month, finds the transformation values for those cells for each month, \n",
    "    # and sums these through time. You are left with an array of shape (isopyncal bins * lats * lons) \n",
    "    # where the array associated with a given isopycnal bin is NaN everywhere except where pot_rho_1 \n",
    "    # was within the bin, there it has a time summed transformation value.\n",
    "    \n",
    "    isopycnal_bins = np.arange(31, 33.5, 0.02) #e.g. first bin going from 31.00 to 31.02\n",
    "    bin_bottoms = isopycnal_bins[:-1]    \n",
    "    pot_rho_1 = ds['pot_rho_1']\n",
    "    X = pot_rho_1.cf['longitude']\n",
    "    Y = pot_rho_1.cf['latitude']\n",
    "    \n",
    "    binned_salt_transformation = xr.DataArray(np.zeros([len(bin_bottoms), len(Y), len(X)]), \n",
    "                                              coords = [bin_bottoms, Y, X], \n",
    "                                              dims = ['isopycnal_bins', Y.name, X.name], \n",
    "                                              name = 'salt_transformation')\n",
    "\n",
    "    binned_heat_transformation = xr.DataArray(np.zeros([len(bin_bottoms), len(Y), len(X)]), \n",
    "                                              coords = [bin_bottoms, Y, X], \n",
    "                                              dims = ['isopycnal_bins', Y.name, X.name], \n",
    "                                              name = 'temp_transformation')\n",
    "    \n",
    "    binned_salt_transformation = binned_salt_transformation.chunk({'isopycnal_bins': 1})\n",
    "    binned_heat_transformation = binned_heat_transformation.chunk({'isopycnal_bins': 1})\n",
    "    \n",
    "    for i in range(len(isopycnal_bins)-1):\n",
    "        bin_mask = pot_rho_1.where(pot_rho_1 <= isopycnal_bins[i+1]).where(pot_rho_1 > isopycnal_bins[i]) * 0 + 1\n",
    "        masked_transform = (salt_transformation * bin_mask).sum('time')\n",
    "        masked_transform = masked_transform.where(masked_transform != 0) \n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_salt_transformation[i, :, :] = masked_transform\n",
    "\n",
    "        masked_transform = (heat_transformation * bin_mask).sum('time')\n",
    "        masked_transform = masked_transform.where(masked_transform != 0) \n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_heat_transformation[i, :, :] = masked_transform\n",
    "\n",
    "    ndays = ds['days_per_month'].sum().values\n",
    "    salt_transformation = binned_salt_transformation / ndays\n",
    "    \n",
    "    c_p = 3992.1 # J kg-1 degC-1\n",
    "    heat_transformation = binned_heat_transformation / c_p / ndays\n",
    "\n",
    "    isopycnal_bin_diff = np.diff(isopycnal_bins)\n",
    "    salt_transformation = salt_transformation / isopycnal_bin_diff[:, np.newaxis, np.newaxis]\n",
    "    heat_transformation = heat_transformation / isopycnal_bin_diff[:, np.newaxis, np.newaxis]\n",
    "    \n",
    "    isopycnal_bin_mid = (isopycnal_bins[1:] + isopycnal_bins[:-1]) / 2\n",
    "    salt_transformation['isopycnal_bins'] = isopycnal_bin_mid\n",
    "    heat_transformation['isopycnal_bins'] = isopycnal_bin_mid\n",
    "    \n",
    "    # Change the sign so that positive means conversion into denser water masses\n",
    "    salt_transformation = -1 * salt_transformation\n",
    "    heat_transformation = -1 * heat_transformation\n",
    "\n",
    "    return salt_transformation, heat_transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43943cc-b08d-4e47-9d54-128712b1ff07",
   "metadata": {},
   "source": [
    "## Using Panan005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3c349a-babb-4c55-b846-1743b44c04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to your experiment of interest\n",
    "expt = 'panant-005-zstar-ACCESSyr2'\n",
    "db = '/home/272/kc5856/databases/honours_test.db'\n",
    "session = cc.database.create_session(db)\n",
    "freq = '1 monthly'\n",
    "\n",
    "# Select time period and region\n",
    "start_time = '2008-01-01'\n",
    "end_time = '2010-12-31'\n",
    "lon_slice = slice(None, None)\n",
    "lat_slice = slice(None, -59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbfcb7-5faa-4d0c-85ab-757656b87b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_variables(expt, freq, start_time, end_time, lon_slice, lat_slice, model = \"mom6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32dbbcc-d025-4f7b-ab48-666e12dd171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a801253-efc9-46ce-a66f-8701a6745c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/binned_salt_transformation_pan005_control.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/binned_heat_transformation_pan005_control.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01eb56-0ad4-44fd-818c-012ddc8b138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_tr = xr.open_dataarray('/g/data/g40/kc5856/access_panan_ssp126_SWMT/binned_salt_transformation_pan005_control.nc', chunks = {'isopycnal_bins': 1})\n",
    "heat_tr = xr.open_dataarray('/g/data/g40/kc5856/access_panan_ssp126_SWMT/binned_heat_transformation_pan005_control.nc', chunks = {'isopycnal_bins': 1})\n",
    "net_tr = salt_tr + heat_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104095d-54f9-4508-be26-98884f693085",
   "metadata": {},
   "source": [
    "Doing the same for the perturbation experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b4be4-5ff3-496f-8868-e7a94cf98195",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For perturbation\n",
    "\n",
    "expt = 'panant-01-zstar-ssp126-MW-only'\n",
    "freq = '1 monthly'\n",
    "\n",
    "# Select period and region\n",
    "start_time = '2008-01-01'\n",
    "end_time = '2010-12-31'\n",
    "lon_slice = slice(None, None)\n",
    "lat_slice = slice(None, -59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f103780-55f7-4d72-8358-236072a0f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_variables(expt, freq, start_time, end_time, lon_slice, lat_slice, model = \"mom6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8791d5c6-2488-4bd0-bcd9-3bb4fa50bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d574d74-adf1-485d-9e66-ccb7d753f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('binned_salt_transformation_melt_pan005_mom6.nc')\n",
    "heat_transformation_binned.to_netcdf('binned_heat_transformation_melt_pan005_mom6.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-24.04] *",
   "language": "python",
   "name": "conda-env-analysis3-24.04-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
