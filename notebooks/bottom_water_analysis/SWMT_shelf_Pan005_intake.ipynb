{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fca44b-e35b-44f8-80fc-e8cfce8407e9",
   "metadata": {},
   "source": [
    "# SWMT on shelf for PanAntarctic 1/20th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b2368-c51c-4826-afd3-d5ae7a36b7ee",
   "metadata": {},
   "source": [
    "This needing intake-ifying due to an issue with `cc.getvar` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd5734cd-4856-4134-aca5-13269b298462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import glob\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cf_xarray as cfxr\n",
    "import cmocean as cm\n",
    "import dask.distributed\n",
    "import gsw\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec \n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.path as mpath\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pdb\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import warnings # ignore these warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0362bbd5-ee91-4d62-8168-80203de4a287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Starting a dask client\n",
    "from os import environ\n",
    "environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(threads_per_worker = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814c4dee-d7ca-45c7-931c-3d59f27de0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables(expt, freq, start_time, end_time, lon_slice, lat_slice, model):\n",
    "\n",
    "    # The models require different diagnostics to calculate the heat and salt fluxes.\n",
    "    # mom6 outputs a net flux, whilst with mom5 we need to work with the separate components.\n",
    "    model_vars = {\n",
    "                    \"mom5\": {\n",
    "                        \"temperature\":           [\"temp\"],\n",
    "                        \"salinity\":              [\"salt\"],\n",
    "                        \"water_flux_into_ocean\": [\"pme_river\"],\n",
    "                        \"salt_flux\":             [\"sfc_salt_flux_ice\", \"sfc_salt_flux_restore\"],\n",
    "                        \"heat_flux\":             [\"sfc_hflux_coupler\", \"sfc_hflux_from_runoff\",\n",
    "                                                  \"frazil_3d_int_z\", \"sfc_hflux_pme\"],\n",
    "                        \"area\":                  [\"area_t\"],\n",
    "                        \"maximum_depth\":         [\"ht\"],\n",
    "                    },\n",
    "                    \"mom6\": {\n",
    "                        \"temperature\":           [\"thetao\"],\n",
    "                        \"salinity\":              [\"so\"],\n",
    "                        \"water_flux_into_ocean\": [\"wfo\"],\n",
    "                        \"salt_flux\":             [\"salt_flux\"],\n",
    "                        \"heat_flux\":             [\"hfds\"],\n",
    "                        \"area\":                  [\"areacello\"],\n",
    "                        \"maximum_depth\":         [\"deptho\"],\n",
    "                    }\n",
    "                }\n",
    "    # Load variables in a dictionary\n",
    "    ds = {}\n",
    "    keys = list(model_vars[model].keys())\n",
    "    for k in keys:\n",
    "        ds[k] = {}\n",
    "        for var in model_vars[model][k]:\n",
    "            if k in [\"area\", \"maximum_depth\"]:\n",
    "                ds[k][var] = cc.querying.getvar(expt, var, session, n = 1) \n",
    "                ds[k][var] = ds[k][var].cf.sel(X = lon_slice, Y = lat_slice)\n",
    "            else:\n",
    "                try:\n",
    "                    ds[k][var] = cc.querying.getvar(expt, var, session,\n",
    "                                                frequency = freq,\n",
    "                                                start_time = start_time,\n",
    "                                                end_time = end_time,\n",
    "                                                chunks = {'time': 1})\n",
    "                    ds[k][var] = ds[k][var].cf.sel(X = lon_slice, Y = lat_slice, time = slice(start_time, end_time))\n",
    "                \n",
    "                    # Correct temperatures (if in K convert to C)\n",
    "                    if k == 'temperature' and np.max(ds[k][var]) > 100:\n",
    "                        ds[k][var] = ds[k][var] - 273.15\n",
    "    \n",
    "                    # If 3D field, grab the surface\n",
    "                    if ds[k][var].cf.axes.get('Z'):\n",
    "                        surface_z = ds[k][var].cf['Z'][0].values\n",
    "                        ds[k][var] = ds[k][var].cf.sel(Z = 0, method = 'nearest')\n",
    "                except Exception as e:\n",
    "                    raise Exception(f\"Data loading error: var={var}, freq={freq}, start_time={start_time}, end_time={end_time}, expt={expt}: {str(e)}\")\n",
    "\n",
    "    # Get temperature and salinity to calculate few other things we'll need later on\n",
    "    SP = ds['salinity'][model_vars[model]['salinity'][0]]\n",
    "    CT = ds['temperature'][model_vars[model]['temperature'][0]]\n",
    "\n",
    "    # Calculate pressure\n",
    "    pressure = gsw.p_from_z(-surface_z, SP.cf['Y']).rename('pressure')\n",
    "\n",
    "    # Calculate absolute salinity\n",
    "    SA = gsw.SA_from_SP(SP, pressure, SP.cf['X'], SP.cf['Y']).rename('SA')\n",
    "\n",
    "    # Ensure we have conservative temperature; Convert MOM6's potential temperature to conservative\n",
    "    if model == 'mom6':\n",
    "        CT = gsw.CT_from_pt(SA, CT)\n",
    "        ds['temperature'][model_vars[model]['temperature'][0]].data = CT.values\n",
    "\n",
    "    # Calculate potential density\n",
    "    pot_rho_0 = gsw.sigma0(SA, CT)#.rename('pot_rho_11')\n",
    "\n",
    "    # Save everything to our dictionary\n",
    "    ds['pressure'] = pressure\n",
    "    ds['SA'] = SA\n",
    "    ds['pot_rho_0'] = pot_rho_0\n",
    "    \n",
    "    # Calculate days per month accounting for leap years\n",
    "    months_standard_noleap = np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "    months_standard_leap = np.array([31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "    if 'ryf' or 'panan' in expt:\n",
    "        nyears = len(np.unique(CT['time.year']))\n",
    "        days_per_month = np.tile(months_standard_noleap, nyears)\n",
    "    elif 'iaf' in expt:\n",
    "        nyears = len(np.unique(CT['time.year']))\n",
    "        if CT['time.year'][0] % 4 == 0:\n",
    "            days_per_month = months_standard_leap\n",
    "        else: \n",
    "            days_per_month = months_standard_noleap\n",
    "        for yr in CT['time.year'][::12][1:]:\n",
    "            if yr % 4 == 0:\n",
    "                days_per_month = np.concatenate([days_per_month, months_standard_leap])\n",
    "            else:\n",
    "                days_per_month = np.concatenate([days_per_month, months_standard_noleap])\n",
    "    days_per_month = xr.DataArray(days_per_month, dims = ['time'], coords = {'time': CT['time']}, name = 'days_per_month')\n",
    "    ds['days_per_month'] = days_per_month\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62958e21-8a7b-4b20-8314-9731eb5b6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_salt_transformation(ds):\n",
    "    \n",
    "    # First retrieve temperature and water_flux as an xarray instead of a dictionary\n",
    "    CT = xr.Dataset(ds['temperature']).to_array().squeeze().drop_vars('variable')\n",
    "\n",
    "    # Multiply the water flux by absolute salinity to get it in the correct units\n",
    "    water_flux_into_ocean = xr.Dataset(ds['water_flux_into_ocean']).to_array().squeeze().drop_vars('variable')\n",
    "    water_flux_into_ocean = ds['SA'] * water_flux_into_ocean\n",
    "\n",
    "    # Caculate the haline contraction coefficient\n",
    "    haline_contraction = gsw.beta(ds['SA'], CT, ds['pressure']).rename('beta')\n",
    "\n",
    "    # Calculate the net salt flux and multiply by 1000 to convert units\n",
    "    net_salt_flux = xr.Dataset(ds['salt_flux']).to_array().sum(dim = 'variable') * 1000\n",
    "\n",
    "    # Note that we also multiply pme_river by absolute salinity to have the correct units\n",
    "    salt_transformation = haline_contraction * (water_flux_into_ocean - net_salt_flux) * ds['days_per_month']\n",
    "    salt_transformation = salt_transformation.load()\n",
    "\n",
    "    return salt_transformation\n",
    "\n",
    "def compute_heat_transformation(ds):\n",
    "\n",
    "    # First retrieve temperature as an xarray instead of a dictionary\n",
    "    CT = xr.Dataset(ds['temperature']).to_array().squeeze().drop_vars('variable')\n",
    "\n",
    "    # Calculate the thermal expansion coefficient \n",
    "    thermal_expansion = gsw.alpha(ds['SA'], CT, ds['pressure']).rename('alpha')\n",
    "    \n",
    "    # Calculate the net surface heating\n",
    "    net_surface_heating = xr.Dataset(ds['heat_flux']).to_array().sum(dim = 'variable')\n",
    "    \n",
    "    # Calculate the heat transformation\n",
    "    heat_transformation = thermal_expansion * net_surface_heating * ds['days_per_month']\n",
    "    heat_transformation = heat_transformation.load()\n",
    "\n",
    "    return heat_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14dee8de-8579-4558-89d1-cfe8f5342da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isopycnal_bins(ds, salt_transformation, heat_transformation):\n",
    "\n",
    "    # Next section does a few things. It cycles through isopycnal bins, determines which cells are \n",
    "    # within the given bin for each month, finds the transformation values for those cells for each month, \n",
    "    # and sums these through time. You are left with an array of shape (isopyncal bins * lats * lons) \n",
    "    # where the array associated with a given isopycnal bin is NaN everywhere except where pot_rho_0\n",
    "    # was within the bin, there it has a time summed transformation value.\n",
    "    \n",
    "    # Choose appropriate bin range\n",
    "    isopycnal_bins = np.arange(31, 33.5, 0.02)  # 125 bins - 31, 33.5, 0.02 (sigma1)\n",
    "    #isopycnal_bins = np.concatenate([np.arange(25.0, 26.5, 0.05), np.arange(26.5, 28.5, 0.02)])  # 130 bins (sigma0)\n",
    "    bin_bottoms = isopycnal_bins[:-1]\n",
    "    isopycnal_bin_mid = (isopycnal_bins[1:] + bin_bottoms) / 2\n",
    "    isopycnal_bin_diff = np.diff(isopycnal_bins)\n",
    "\n",
    "    pot_rho_0 = ds['pot_rho_0']\n",
    "\n",
    "    results_salt = []\n",
    "    results_heat = []\n",
    "\n",
    "    for i in range(len(bin_bottoms)):\n",
    "        # Create binary mask for each bin\n",
    "        bin_mask = xr.where((pot_rho_0 > bin_bottoms[i]) & (pot_rho_0 <= isopycnal_bins[i + 1]), 1, np.nan)\n",
    "\n",
    "        # Multiply and sum over time\n",
    "        salt_sum = (salt_transformation * bin_mask).sum(dim='time')\n",
    "        heat_sum = (heat_transformation * bin_mask).sum(dim='time')\n",
    "\n",
    "        results_salt.append(salt_sum.expand_dims({'isopycnal_bins': [isopycnal_bin_mid[i]]}))\n",
    "        results_heat.append(heat_sum.expand_dims({'isopycnal_bins': [isopycnal_bin_mid[i]]}))\n",
    "\n",
    "    # Concatenate results along isopycnal dimension\n",
    "    salt_transformation = xr.concat(results_salt, dim='isopycnal_bins')\n",
    "    heat_transformation = xr.concat(results_heat, dim='isopycnal_bins')\n",
    "\n",
    "    # Normalise by number of days and bin thickness\n",
    "    ndays = ds['days_per_month'].sum()\n",
    "    c_p = 3992.1 # J kg-1 degC-1\n",
    "\n",
    "    salt_transformation /= ndays\n",
    "    heat_transformation /= (c_p * ndays)\n",
    "\n",
    "    salt_transformation /= isopycnal_bin_diff[:, np.newaxis, np.newaxis]\n",
    "    heat_transformation /= isopycnal_bin_diff[:, np.newaxis, np.newaxis]\n",
    "\n",
    "    # Overwrite zeros with NANs \n",
    "    # (Note: the code within the for-loop should provide nans but lazy computing with dask can sometimes give unpredictable results)\n",
    "    salt_transformation = salt_transformation.where(salt_transformation != 0)\n",
    "    heat_transformation = heat_transformation.where(heat_transformation != 0)\n",
    "\n",
    "    # Change the sign so that positive means conversion into denser water masses\n",
    "    salt_transformation *= -1\n",
    "    heat_transformation *= -1\n",
    "\n",
    "    # Renaming\n",
    "    salt_transformation.name = \"salt_transformation\"\n",
    "    heat_transformation.name = \"heat_transformation\"\n",
    "\n",
    "    return salt_transformation.load(), heat_transformation.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a4ac7-1543-4898-a4d9-c0af660ba496",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Opening the saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694b745-6335-4212-bafe-098421a15e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the saved files\n",
    "salt_files_C = np.sort(glob.glob('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_*'))\n",
    "heat_files_C = np.sort(glob.glob('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_*'))\n",
    "\n",
    "salt_files_M = np.sort(glob.glob('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_M_*'))\n",
    "heat_files_M = np.sort(glob.glob('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_M_*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c10e3-fdc5-4612-b420-afdcbb8d3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_tr_C = xr.open_mfdataset(salt_files_C, concat_dim='time', combine='nested', chunks={'time': 1, 'yh': 100, 'xh': 100})\n",
    "heat_tr_C = xr.open_mfdataset(heat_files_C, concat_dim='time', combine='nested', chunks={'time': 1, 'yh': 100, 'xh': 100})\n",
    "salt_tr_C = salt_tr_C.to_array().squeeze()\n",
    "heat_tr_C = heat_tr_C.to_array().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3abc94-2c58-4371-a22a-4722774fe2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_tr_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbce5a8-0f88-416c-8b64-0c64f64688d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_tr_M = xr.open_mfdataset(salt_files_M, concat_dim='time', combine='nested', chunks={'time': 1, 'yh': 100, 'xh': 100})\n",
    "heat_tr_M = xr.open_mfdataset(heat_files_M, concat_dim='time', combine='nested', chunks={'time': 1, 'yh': 100, 'xh': 100})\n",
    "salt_tr_M = salt_tr_M.to_array().squeeze()\n",
    "heat_tr_M = heat_tr_M.to_array().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999773e-39a9-4ac9-b220-1de319ee2acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_tr_C = salt_tr_C + heat_tr_C\n",
    "net_tr_M = salt_tr_M + heat_tr_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae65a9d5-7d7e-48aa-85a6-c2773d296769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining the data separately for variables like area, depth, etc.\n",
    "expt_con = 'panant-005-zstar-ACCESSyr2'\n",
    "db = '/home/272/kc5856/databases/honours_test.db'\n",
    "session = cc.database.create_session(db)\n",
    "freq = '1 monthly'\n",
    "\n",
    "lon_slice = slice(None, None)\n",
    "lat_slice = slice(None, -59)\n",
    "\n",
    "start_time = '2001-01-01'\n",
    "end_time = '2001-12-31'\n",
    "\n",
    "ds_cont = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebfd21-5159-4bb5-9f43-e1d6a8fc8274",
   "metadata": {},
   "source": [
    "#### Antarctic shelf dense water formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ba1d4-fb5e-4438-8099-daf0646c4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shelf_mask_isobath(var, model_dict):\n",
    "\n",
    "    paths = {\n",
    "             \"mom5\": \"/g/data/ik11/grids/Antarctic_slope_contour_1000m.npz\",\n",
    "             \"mom6_01\": \"/g/data/ik11/grids/Antarctic_slope_contour_1000m_MOM6_01deg.nc\",\n",
    "            \"mom6_005\": \"/g/data/ik11/grids/Antarctic_slope_contour_1000m_MOM6_005deg.nc\"\n",
    "             }\n",
    "\n",
    "    var = var.cf.sel({'latitude': slice(-90, -59)})\n",
    "\n",
    "    if paths[model_dict][-3:] == '.nc':\n",
    "        shelf_mask = xr.open_dataset(paths[model_dict])['contour_masked_above']\n",
    "    else:\n",
    "        contour_file = np.load(paths[model_dict])\n",
    "        shelf_mask = xr.DataArray(contour_file['contour_masked_above'],\n",
    "                                  coords = var.coords, \n",
    "                                  dims = var.dims,\n",
    "                                  name = 'contour_masked_above')\n",
    "    \n",
    "    shelf_mask = xr.where(shelf_mask == 0, 1, 0)\n",
    "    masked_var = var * shelf_mask\n",
    "    \n",
    "    return masked_var, shelf_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a20dfe-88c3-4179-b39a-dd3af1865119",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = xr.Dataset(ds_cont['maximum_depth']).to_array().squeeze()\n",
    "land_mask = (0 * depth).fillna(1)\n",
    "depth_shelf, shelf_mask = shelf_mask_isobath(depth, 'mom6_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d770d0-c95f-40dd-b937-0ca642cd2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = xr.Dataset(ds_cont['area']).to_array().squeeze().drop_vars('variable')\n",
    "varr = xr.Dataset(ds_cont['salinity']).to_array().squeeze().isel(time=0)\n",
    "area_corr = (area*(varr*0+1)).drop_vars('variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57cf84e-c9b7-43cf-9d59-be88f958c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_corr = area_corr.drop_vars(['time','z_l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6871d1-fa03-466e-bc22-3aba7f0bb9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mask\n",
    "area_corr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdab856-e1df-469d-ac40-52031aa9e777",
   "metadata": {},
   "source": [
    "Corrected area not needed because it is already being multiplied with a variable with the correct mask below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb24496-4e1d-417a-bb97-45d5c4988064",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_C = (net_tr_C * area_corr / 1e6).where(shelf_mask == 1)\n",
    "heat_shelf_C = (heat_tr_C * area_corr / 1e6).where(shelf_mask == 1)\n",
    "salt_shelf_C = (salt_tr_C * area_corr / 1e6).where(shelf_mask == 1)\n",
    "\n",
    "swmt_shelf_C = swmt_shelf_C.chunk({'time': 1, 'yh': 100, 'xh': 100})\n",
    "heat_shelf_C = heat_shelf_C.chunk({'time': 1, 'yh': 100, 'xh': 100})\n",
    "salt_shelf_C = salt_shelf_C.chunk({'time': 1, 'yh': 100, 'xh': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4816f8a-8d4f-4e72-8ed4-f4fc84b0bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swmt_shelf_C.cf.sum(['xh', 'yh']).astype('float32') # if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81090e2-5cbf-42b3-ad1f-d82f5a3be7fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "swmt_shelf_sum_C = swmt_shelf_C.cf.sum(['xh', 'yh']).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e1e3e-e262-454a-bc42-3967d25608ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time mean\n",
    "swmt_shelf_sum_ave_C = swmt_shelf_sum_C.mean(dim='time')\n",
    "\n",
    "for da in [swmt_shelf_sum_ave_C]:#, heat_shelf_sum_ave_C, salt_shelf_sum_ave_C]:\n",
    "    da.attrs[\"units\"] = \"Sv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f555c-7ae4-4e4a-b951-e1f6d50bfc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_M = (net_tr_M * area_corr / 1e6).where(shelf_mask == 1)\n",
    "heat_shelf_M = (heat_tr_M * area_corr / 1e6).where(shelf_mask == 1)\n",
    "salt_shelf_M = (salt_tr_M * area_corr / 1e6).where(shelf_mask == 1)\n",
    "\n",
    "swmt_shelf_M = swmt_shelf_M.chunk({'time': 1, 'yh': 100, 'xh': 100})\n",
    "heat_shelf_M = heat_shelf_M.chunk({'time': 1, 'yh': 100, 'xh': 100})\n",
    "salt_shelf_M = salt_shelf_M.chunk({'time': 1, 'yh': 100, 'xh': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424b7aa-e8d7-4a57-9694-19466d1eb965",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_sum_M = swmt_shelf_M.cf.sum(['xh', 'yh']).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408225d6-d0da-4783-aed2-ab58ae1aa6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time mean\n",
    "swmt_shelf_sum_ave_M = swmt_shelf_sum_M.mean(dim='time')\n",
    "\n",
    "for da in [swmt_shelf_sum_ave_M]: #, heat_shelf_sum_ave_M, salt_shelf_sum_ave_M]:\n",
    "    da.attrs[\"units\"] = \"Sv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fbc741-33b0-4c96-ae6f-237799c53e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_sum_ave_C # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f32d8ef-40ca-4f4b-a1e0-9b2512d0decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_sum_ave_C.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3b289-237a-41dd-b0b5-21fa9b42e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_sum_ave_M.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f3a724-032d-4d69-ac77-b633c330082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25% and 75% thresholds\n",
    "## Replace when using new data\n",
    "cont_d25 = 32.65\n",
    "cont_d75 = 32.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98f66a-15ed-45fe-b547-3eb4c2e3271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(4.5, 5.33))\n",
    "\n",
    "ax1.plot(swmt_shelf_sum_ave_C, swmt_shelf_sum_ave_C['isopycnal_bins'], color = 'k', label='Control: 3.70 Sv')\n",
    "ax1.plot(swmt_shelf_sum_ave_M, swmt_shelf_sum_ave_M['isopycnal_bins'], color = 'r', label='Meltwater: 3.11 Sv')\n",
    "ax1.plot([0, 0], [31, 33.2], 'k', linewidth=0.5)\n",
    "ax1.plot([-5, 15], [cont_d25, cont_d25], 'k--', linewidth=1)\n",
    "ax1.plot([-5, 15], [cont_d75, cont_d75], 'k--', linewidth=1)\n",
    "ax1.set_ylim((33.2, 31))\n",
    "ax1.set_xlim((-1.5, 10))\n",
    "ax1.yaxis.set_label_position(\"right\")\n",
    "ax1.yaxis.tick_right()\n",
    "ax1.set_ylabel('Density $\\sigma_1$ (kg m$^{-3}$)')\n",
    "ax1.set_xlabel('Surface water-mass transformation (Sv)')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d1e89-b7e3-468f-bc1a-2ff0569b3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_sum_ave_C.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/plots/swmt_shelf_sum_ave_C_pan005.nc')\n",
    "swmt_shelf_sum_ave_M.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/plots/swmt_shelf_sum_ave_M_pan005.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85c6de-e5ba-4b04-b989-dea0b6675fe1",
   "metadata": {},
   "source": [
    "#### SWMT map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007c9a0-4927-47a1-8dcc-c186dcd1bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_density = 32.58 ## Replace when using new data\n",
    "shelf_subduction_plot_C = net_tr_C.sel(isopycnal_bins = transformation_density, method = 'nearest') * 1e5\n",
    "swmt_xt_C = depth.cf['X']\n",
    "swmt_yt_C = depth.cf['Y']\n",
    "\n",
    "shelf_subduction_plot_M = net_tr_M.sel(isopycnal_bins = transformation_density, method = 'nearest') * 1e5\n",
    "swmt_xt_M = depth.cf['X']\n",
    "swmt_yt_M = depth.cf['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6340b-dab9-48ab-a54f-630d5fdb759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf_subduction_plot_C.astype('float32').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0fc11-f44d-4146-8d0f-10b049307579",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf_subduction_plot_M.astype('float32').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b611bd91-8060-4b11-af2d-cb0d3662741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_xt = swmt_xt_M.fillna(0) - swmt_xt_C.fillna(0)\n",
    "anom_yt = swmt_yt_M.fillna(0) - swmt_yt_C.fillna(0)\n",
    "shelf_subduction_plot_anom = shelf_subduction_plot_M.fillna(0) - shelf_subduction_plot_C.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f495286-0f4f-4587-8beb-f002894caab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking time means\n",
    "shelf_subduction_plot_ave_anom = shelf_subduction_plot_anom.mean(dim='time')\n",
    "shelf_subduction_plot_ave_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f75bf5-3e31-44ed-aca1-ea93014817e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf_subduction_plot_ave_anom = shelf_subduction_plot_ave_anom.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea87bc2-a3f5-48c6-8177-15027fbcc667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check before saving\n",
    "shelf_subduction_plot_ave_anom.plot(vmin=-2,vmax=2, cmap=cm.cm.balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c92ad-8b90-4d53-8dfc-25139dd4c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf_subduction_plot_ave_anom.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/plots/swmt_shelf_plot_anom_pan005.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eebdffa-be6c-4aee-bd84-18bd274890b4",
   "metadata": {},
   "source": [
    "#### Finding the 25% and 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d740f-9674-433a-a468-cf221dbcf28f",
   "metadata": {},
   "source": [
    "Control max = 8.05866571 Sv (at density 32.41).  \n",
    "- 25% of max (2.0146664275 Sv) = 32.65\n",
    "- 75% of max (6.0439992825 Sv) = 32.51\n",
    "- Control total transport in this slice = 25.8736142 Sv\n",
    "- Mean of control in this slice = 3.6962306 Sv.\n",
    "      \n",
    "Melt max = 7.71676875 Sv (at density 32.41).  \n",
    "- 25% of max (1.9291921875 Sv) = BLANK\n",
    "- 75% of max (5.7875765625) = BLANK\n",
    "- Melt total transport in this slice = 21.77198215 Sv.\n",
    "- Mean of meltwater in this region = 3.11028317 Sv.\n",
    "\n",
    "We just use the control lines as our formation region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8e10a-0b05-42b3-938d-d94c36bb3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding maximum\n",
    "swmt_shelf_sum_ave_C.sel(isopycnal_bins=slice(32.55,32.69)) # Pick slice based on plot, test for max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21510a-45d5-4210-b7f5-5db03509ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = \n",
    "swmt_shelf_sum_ave_C.isel(isopycnal_bins=max_value).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180c392-56a4-45cf-8978-caa6a6f3b925",
   "metadata": {},
   "source": [
    "Finding the sums: (change density values below to match 25 and 75 thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20534b99-8723-4089-bcb0-e76cb29b6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_25 = 32.65\n",
    "val_75 = 32.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c3460-5553-4731-97b7-672d96ed1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_sum_ave_C.sel(isopycnal_bins=slice(val_75,val_25)).compute().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c7560-4000-4500-ad09-6e6233aca939",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_sum_ave_M.sel(isopycnal_bins=slice(val_75,val_25)).compute().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856eba94-181c-42d9-ac2d-5a54af5bb9e7",
   "metadata": {},
   "source": [
    "#### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a3110-341c-419b-afca-7150beb729fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_time_C = swmt_shelf_sum_C.sel(isopycnal_bins=slice(val_75,val_25)).mean('isopycnal_bins').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406dec9d-595f-4a99-a45f-ab385168100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_time_M = swmt_shelf_sum_M.sel(isopycnal_bins=slice(val_75,val_25)).mean('isopycnal_bins').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6211d466-f68a-44ec-852a-e4b795738e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_time_C.plot(label=\"Control\")\n",
    "swmt_shelf_time_M.plot(label=\"Meltwater\")\n",
    "plt.ylabel(\"Surface water mass transformation (Sv)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.title(\"Panan01 Surface Water Mass Transformation over 25-75% range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf109f-5631-4bbf-ba67-34456f90309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "swmt_shelf_time_C.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/SWMT_timeseries/swmt_shelf_time_pan005_C.nc')\n",
    "swmt_shelf_time_M.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/SWMT_timeseries/swmt_shelf_time_pan005_M.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521b63e-e903-4f8d-b038-148991df76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_time_anom = swmt_shelf_time_M - swmt_shelf_time_C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221410e2-5287-4bba-875f-62b7ebb24ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_time_anom.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df94f1-dd8f-433e-9e4a-9241f6477b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmt_shelf_time_anom.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/SWMT_timeseries/swmt_shelf_time_pan005_anom.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf4858-6c01-4d3d-9d16-c8fd3e42748d",
   "metadata": {},
   "source": [
    "## Saving per year via manual method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f9db64f-7e5f-4ec6-917f-d1d22bc2c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to your experiment of interest\n",
    "expt_con = 'panant-005-zstar-ACCESSyr2'\n",
    "db = '/home/272/kc5856/databases/honours_test.db'\n",
    "session = cc.database.create_session(db)\n",
    "freq = '1 monthly'\n",
    "\n",
    "# Select time period and region\n",
    "lon_slice = slice(None, None)\n",
    "lat_slice = slice(None, -59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52164ac-bc7f-44f0-b739-3b7bc823a713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data loading error: var=thetao, freq=1 monthly, start_time=2001-01-01, end_time=2001-12-31, expt=panant-005-zstar-ACCESSyr2: Every dimension requires a corresponding 1D coordinate and index for inferring concatenation order but the coordinate 'rho2_l' has no corresponding index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m, in \u001b[0;36mget_variables\u001b[0;34m(expt, freq, start_time, end_time, lon_slice, lat_slice, model)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     ds[k][var] \u001b[38;5;241m=\u001b[39m \u001b[43mcc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquerying\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetvar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     ds[k][var] \u001b[38;5;241m=\u001b[39m ds[k][var]\u001b[38;5;241m.\u001b[39mcf\u001b[38;5;241m.\u001b[39msel(X \u001b[38;5;241m=\u001b[39m lon_slice, Y \u001b[38;5;241m=\u001b[39m lat_slice, time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_time, end_time))\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/cosima_cookbook/querying.py:368\u001b[0m, in \u001b[0;36mgetvar\u001b[0;34m(expt, variable, session, ncfile, start_time, end_time, n, frequency, attrs, attrs_unique, return_dataset, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m ncfiles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mstr\u001b[39m(f\u001b[38;5;241m.\u001b[39mNCFile\u001b[38;5;241m.\u001b[39mncfile_path) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m ncfiles)\n\u001b[0;32m--> 368\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_mfdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mncfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mby_coords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxr_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dataset:\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/xarray/backends/api.py:1606\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m combine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby_coords\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1604\u001b[0m     \u001b[38;5;66;03m# Redo ordering from coordinates, ignoring how they were ordered\u001b[39;00m\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;66;03m# previously\u001b[39;00m\n\u001b[0;32m-> 1606\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_by_coords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/xarray/core/combine.py:961\u001b[0m, in \u001b[0;36mcombine_by_coords\u001b[0;34m(data_objects, compat, data_vars, coords, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;66;03m# Perform the multidimensional combine on each group of data variables\u001b[39;00m\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;66;03m# before merging back together\u001b[39;00m\n\u001b[0;32m--> 961\u001b[0m     concatenated_grouped_by_data_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_combine_single_variable_hypercube\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgrouped_by_vars\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m    975\u001b[0m     concatenated_grouped_by_data_vars,\n\u001b[1;32m    976\u001b[0m     compat\u001b[38;5;241m=\u001b[39mcompat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    979\u001b[0m     combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    980\u001b[0m )\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/xarray/core/combine.py:962\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;66;03m# Perform the multidimensional combine on each group of data variables\u001b[39;00m\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;66;03m# before merging back together\u001b[39;00m\n\u001b[1;32m    961\u001b[0m     concatenated_grouped_by_data_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 962\u001b[0m         \u001b[43m_combine_single_variable_hypercube\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mvars\u001b[39m, datasets_with_same_vars \u001b[38;5;129;01min\u001b[39;00m grouped_by_vars\n\u001b[1;32m    972\u001b[0m     )\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m    975\u001b[0m     concatenated_grouped_by_data_vars,\n\u001b[1;32m    976\u001b[0m     compat\u001b[38;5;241m=\u001b[39mcompat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    979\u001b[0m     combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    980\u001b[0m )\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/xarray/core/combine.py:622\u001b[0m, in \u001b[0;36m_combine_single_variable_hypercube\u001b[0;34m(datasets, fill_value, data_vars, coords, compat, join, combine_attrs)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one Dataset is required to resolve variable names \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    619\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor combined hypercube.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    620\u001b[0m     )\n\u001b[0;32m--> 622\u001b[0m combined_ids, concat_dims \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_concat_order_from_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;66;03m# check that datasets form complete hypercube\u001b[39;00m\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/xarray/core/combine.py:97\u001b[0m, in \u001b[0;36m_infer_concat_order_from_coords\u001b[0;34m(datasets)\u001b[0m\n\u001b[1;32m     92\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvery dimension requires a corresponding 1D coordinate \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand index for inferring concatenation order but the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinate \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no corresponding index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# TODO (benbovy, flexible indexes): support flexible indexes?\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Every dimension requires a corresponding 1D coordinate and index for inferring concatenation order but the coordinate 'rho2_l' has no corresponding index",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2001-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2001-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpt_con\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmom6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m ds\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36mget_variables\u001b[0;34m(expt, freq, start_time, end_time, lon_slice, lat_slice, model)\u001b[0m\n\u001b[1;32m     51\u001b[0m                     ds[k][var] \u001b[38;5;241m=\u001b[39m ds[k][var]\u001b[38;5;241m.\u001b[39mcf\u001b[38;5;241m.\u001b[39msel(Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 53\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData loading error: var=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, freq=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfreq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, start_time=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, end_time=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expt=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Get temperature and salinity to calculate few other things we'll need later on\u001b[39;00m\n\u001b[1;32m     56\u001b[0m SP \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalinity\u001b[39m\u001b[38;5;124m'\u001b[39m][model_vars[model][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalinity\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;31mException\u001b[0m: Data loading error: var=thetao, freq=1 monthly, start_time=2001-01-01, end_time=2001-12-31, expt=panant-005-zstar-ACCESSyr2: Every dimension requires a corresponding 1D coordinate and index for inferring concatenation order but the coordinate 'rho2_l' has no corresponding index"
     ]
    }
   ],
   "source": [
    "# Checking get_var function\n",
    "start_time = '2001-01-01'\n",
    "end_time = '2001-12-31'\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8f00087c-ffa9-4397-b466-f55125af840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Combined catalog saved to /home/272/kc5856/pan005_combined.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths to catalogs\n",
    "control_json = Path('/home/272/kc5856/catalog_dir/panant_005_zstar_access_yr2.json')\n",
    "melt_json = Path('/home/272/kc5856/panantrial/panant_005_zstar_MWonly.json')\n",
    "combined_json = Path('/home/272/kc5856/pan005_combined.json')\n",
    "combined_csv = Path('/home/272/kc5856/pan005_combined.csv')\n",
    "\n",
    "# Load both JSON files\n",
    "with open(control_json, 'r') as f:\n",
    "    control = json.load(f)\n",
    "\n",
    "with open(melt_json, 'r') as f:\n",
    "    melt = json.load(f)\n",
    "\n",
    "# Remove 'file:' prefix if present\n",
    "control_catalog_file = control[\"catalog_file\"].replace(\"file:\", \"\")\n",
    "melt_catalog_file = melt[\"catalog_file\"].replace(\"file:\", \"\")\n",
    "\n",
    "# Get absolute CSV paths\n",
    "control_csv = Path(control_catalog_file)\n",
    "melt_csv = Path(melt_catalog_file)\n",
    "\n",
    "# Read both CSVs\n",
    "df_control = pd.read_csv(control_csv)\n",
    "df_melt = pd.read_csv(melt_csv)\n",
    "\n",
    "# Add a column to identify source (optional but useful)\n",
    "df_control[\"source\"] = \"control\"\n",
    "df_melt[\"source\"] = \"meltwater\"\n",
    "\n",
    "# Add a column to identify source (optional but useful)\n",
    "df_control[\"experiment\"] = \"control\"\n",
    "df_melt[\"experiment\"] = \"meltwater\"\n",
    "\n",
    "\n",
    "# Combine them\n",
    "df_combined = pd.concat([df_control, df_melt], ignore_index=True)\n",
    "\n",
    "# Save combined CSV\n",
    "df_combined.to_csv(combined_csv, index=False)\n",
    "\n",
    "# Create new JSON (copy from one and update catalog_file)\n",
    "combined_metadata = control.copy()\n",
    "combined_metadata[\"catalog_file\"] = combined_csv.name  # relative path\n",
    "\n",
    "# Save combined JSON\n",
    "with open(combined_json, 'w') as f:\n",
    "    json.dump(combined_metadata, f, indent=2)\n",
    "\n",
    "print(f\" Combined catalog saved to {combined_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "86c6e325-96b9-46c5-877d-5271fd67e0ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sources' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cat \u001b[38;5;241m=\u001b[39m intake\u001b[38;5;241m.\u001b[39mopen_esm_datastore(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/272/kc5856/pan005_combined.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m cat\u001b[38;5;241m.\u001b[39msearch(source\u001b[38;5;241m=\u001b[39m\u001b[43msources\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sources' is not defined"
     ]
    }
   ],
   "source": [
    "cat = intake.open_esm_datastore(\"/home/272/kc5856/pan005_combined.json\")\n",
    "cat.search(source=sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3637cd03-c6cc-42ea-9425-911855936857",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m ds_dict \u001b[38;5;241m=\u001b[39m selection\u001b[38;5;241m.\u001b[39mto_dataset_dict()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# If your search returns just one experiment/dataset:\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m ds_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mds_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# get the single xarray.Dataset\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Open the esm datastore catalog\n",
    "expt_cont = intake.open_esm_datastore('/home/272/kc5856/catalog_dir/panant_005_zstar_access_yr2.json')\n",
    "\n",
    "# Suppose you want to select all variables for your experiment (frequency, etc.)\n",
    "# Here is an example to get all variables with frequency 'monthly':\n",
    "selection = expt_cont.search(frequency='monthly')\n",
    "\n",
    "# Open dataset(s) as xarray dataset dictionary (or combined dataset)\n",
    "ds_dict = selection.to_dataset_dict()\n",
    "\n",
    "# If your search returns just one experiment/dataset:\n",
    "ds_obj = list(ds_dict.values())[0]  # get the single xarray.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43516a32-6345-447e-8849-00a29fb36bfb",
   "metadata": {},
   "source": [
    "### First doing the control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87bd0837-d624-4ded-a0de-e11ee4c5d556",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data loading error: var=thetao, freq=1mon, start_time=2001-01-01, end_time=2001-12-31, expt=panant_005_zstar_access_yr2: 'key=panant_005_zstar_access_yr2 not found in catalog. You can access the list of valid keys via the .keys() method.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/intake_esm/core.py:241\u001b[0m, in \u001b[0;36mesm_datastore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_entries\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'panant_005_zstar_access_yr2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m, in \u001b[0;36mget_variables\u001b[0;34m(expt, freq, start_time, end_time, lon_slice, lat_slice, model)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     ds[k][var] \u001b[38;5;241m=\u001b[39m \u001b[43mcat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexpt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msearch(variable\u001b[38;5;241m=\u001b[39mvar, frequency\u001b[38;5;241m=\u001b[39mfreq)\u001b[38;5;241m.\u001b[39mto_dask(\n\u001b[1;32m     40\u001b[0m         xarray_open_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunks\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m}, \n\u001b[1;32m     42\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_timedelta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         })[var]\n\u001b[1;32m     44\u001b[0m     ds[k][var] \u001b[38;5;241m=\u001b[39m ds[k][var]\u001b[38;5;241m.\u001b[39mcf\u001b[38;5;241m.\u001b[39msel(\n\u001b[1;32m     45\u001b[0m         X \u001b[38;5;241m=\u001b[39m lon_slice, Y \u001b[38;5;241m=\u001b[39m lat_slice, \n\u001b[1;32m     46\u001b[0m         time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_time, end_time))\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/pydantic/deprecated/decorator.py:55\u001b[0m, in \u001b[0;36mvalidate_arguments.<locals>.validate.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(_func)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/pydantic/deprecated/decorator.py:150\u001b[0m, in \u001b[0;36mValidatedFunction.call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_model_instance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/pydantic/deprecated/decorator.py:222\u001b[0m, in \u001b[0;36mValidatedFunction.execute\u001b[0;34m(self, m)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvar_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/g/data/xp65/public/apps/med_conda/envs/analysis3-24.07/lib/python3.11/site-packages/intake_esm/core.py:274\u001b[0m, in \u001b[0;36mesm_datastore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entries[key]\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in catalog. You can access the list of valid keys via the .keys() method.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'key=panant_005_zstar_access_yr2 not found in catalog. You can access the list of valid keys via the .keys() method.'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2001-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2001-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpt_con\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmom6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m salt_transformation \u001b[38;5;241m=\u001b[39m compute_salt_transformation(ds)\n\u001b[1;32m      8\u001b[0m heat_transformation \u001b[38;5;241m=\u001b[39m compute_heat_transformation(ds)\n",
      "Cell \u001b[0;32mIn[3], line 57\u001b[0m, in \u001b[0;36mget_variables\u001b[0;34m(expt, freq, start_time, end_time, lon_slice, lat_slice, model)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     ds[k][var] \u001b[38;5;241m=\u001b[39m ds[k][var]\u001b[38;5;241m.\u001b[39mcf\u001b[38;5;241m.\u001b[39msel(Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 57\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData loading error: var=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, freq=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfreq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, start_time=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, end_time=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expt=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Get temperature and salinity to calculate few other things we'll need later on\u001b[39;00m\n\u001b[1;32m     60\u001b[0m SP \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalinity\u001b[39m\u001b[38;5;124m'\u001b[39m][model_vars[model][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalinity\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;31mException\u001b[0m: Data loading error: var=thetao, freq=1mon, start_time=2001-01-01, end_time=2001-12-31, expt=panant_005_zstar_access_yr2: 'key=panant_005_zstar_access_yr2 not found in catalog. You can access the list of valid keys via the .keys() method.'"
     ]
    }
   ],
   "source": [
    "# Painfully manual don't mind this 1\n",
    "start_time = '2001-01-01'\n",
    "end_time = '2001-12-31'\n",
    "\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_01.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_01.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68eee3-412a-4c43-847c-a894f1520867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 2\n",
    "\n",
    "start_time = '2002-01-01'\n",
    "end_time = '2002-12-31'\n",
    "\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_02.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_02.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fafe65e-ff4b-4822-9585-0fe18c606d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 3\n",
    "\n",
    "start_time = '2003-01-01'\n",
    "end_time = '2003-12-31'\n",
    "\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_03.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_03.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf57cb-b05b-4008-ba65-8c08b5dc3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 4\n",
    "\n",
    "start_time = '2004-01-01'\n",
    "end_time = '2004-12-31'\n",
    "\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_04.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_04.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df6b07-e83b-4ef1-88a3-45601eaf97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 5\n",
    "\n",
    "start_time = '2005-01-01'\n",
    "end_time = '2005-12-31'\n",
    "\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_05.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_05.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0fff2-ef53-4f00-8f84-477cafd0a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 6\n",
    "\n",
    "start_time = '2006-01-01'\n",
    "end_time = '2006-12-31'\n",
    "\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_06.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_06.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0643d-fb7f-4f71-841b-b484f9309960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 7\n",
    "\n",
    "start_time = '2007-01-01'\n",
    "end_time = '2007-12-31'\n",
    "\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_07.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_07.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861d6d8-9339-4f44-9b6d-4be9d3019dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 8\n",
    "\n",
    "start_time = '2008-01-01'\n",
    "end_time = '2008-12-31'\n",
    "\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_08.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_08.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95cca8-a6e1-4e0f-bc37-5001ee225a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 9\n",
    "\n",
    "start_time = '2009-01-01'\n",
    "end_time = '2009-12-31'\n",
    "\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_09.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_09.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7ad43-11ee-4f4a-a4ef-7137ad3de906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 10\n",
    "\n",
    "start_time = '2010-01-01'\n",
    "end_time = '2010-12-31'\n",
    "\n",
    "ds = get_variables(expt_con, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_salt_trans_pan005_C_10.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan005_SWMT_shelf/binned_heat_trans_pan005_C_10.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe91de-588f-4379-b58f-a7e1519cc33f",
   "metadata": {},
   "source": [
    "#### Second doing the perturbation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f9e21-58fc-4825-8668-a9ba894c7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to your experiment of interest\n",
    "expt_melt = 'panant-005-zstar-ssp126-MW-only'\n",
    "db = '/home/272/kc5856/databases/honours_test.db'\n",
    "session = cc.database.create_session(db)\n",
    "freq = '1 monthly'\n",
    "\n",
    "# Select time period and region\n",
    "lon_slice = slice(None, None)\n",
    "lat_slice = slice(None, -59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9816989-acf6-4459-9cb5-c038b7d4e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm its working\n",
    "start_time = '2001-01-01'\n",
    "end_time = '2001-12-31'\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fdf7f2-e080-4372-875b-65b12c76420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 1\n",
    "\n",
    "start_time = '2001-01-01'\n",
    "end_time = '2001-12-31'\n",
    "\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_salt_trans_pan01_M_01.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_heat_trans_pan01_M_01.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea1811-501d-43fa-835f-94729fc3880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 2\n",
    "\n",
    "start_time = '2002-01-01'\n",
    "end_time = '2002-12-31'\n",
    "\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_salt_trans_pan01_M_02.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_heat_trans_pan01_M_02.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11277d2d-7b4e-4238-b42c-d88549c0f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 3\n",
    "\n",
    "start_time = '2003-01-01'\n",
    "end_time = '2003-12-31'\n",
    "\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_salt_trans_pan01_M_03.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_heat_trans_pan01_M_03.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28816e2-7052-4a2e-85dc-c83d92014202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 4\n",
    "\n",
    "start_time = '2004-01-01'\n",
    "end_time = '2004-12-31'\n",
    "\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_salt_trans_pan01_M_04.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_heat_trans_pan01_M_04.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091a496-c08d-4658-9d35-6e6e281aed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 5\n",
    "\n",
    "start_time = '2005-01-01'\n",
    "end_time = '2005-12-31'\n",
    "\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_salt_trans_pan01_M_05.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_heat_trans_pan01_M_05.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204fa17-99b3-4fcf-99ef-5fb4093f14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 6\n",
    "\n",
    "start_time = '2006-01-01'\n",
    "end_time = '2006-12-31'\n",
    "\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_salt_trans_pan01_M_06.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_heat_trans_pan01_M_06.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14460a88-16e9-4cd3-a1f6-e743ae53b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 7\n",
    "\n",
    "start_time = '2007-01-01'\n",
    "end_time = '2007-12-31'\n",
    "\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_salt_trans_pan01_M_07.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_heat_trans_pan01_M_07.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0dfb95-214a-4e19-a234-8b6f362916f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 8\n",
    "\n",
    "start_time = '2008-01-01'\n",
    "end_time = '2008-12-31'\n",
    "\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_salt_trans_pan01_M_08.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_heat_trans_pan01_M_08.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0405cc-29f4-4092-9936-15d5deb730da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 9\n",
    "\n",
    "start_time = '2009-01-01'\n",
    "end_time = '2009-12-31'\n",
    "\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_salt_trans_pan01_M_09.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_heat_trans_pan01_M_09.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6454dc-9b64-4eea-b002-e695eaae2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Painfully manual don't mind this 10\n",
    "\n",
    "start_time = '2010-01-01'\n",
    "end_time = '2010-12-31'\n",
    "\n",
    "ds = get_variables(expt_melt, freq, start_time, end_time, lon_slice, lat_slice, model = 'mom6')\n",
    "           \n",
    "salt_transformation = compute_salt_transformation(ds)\n",
    "heat_transformation = compute_heat_transformation(ds)\n",
    "\n",
    "salt_transformation_binned, heat_transformation_binned = isopycnal_bins(ds, salt_transformation, heat_transformation)\n",
    "\n",
    "salt_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_salt_trans_pan01_M_10.nc')\n",
    "heat_transformation_binned.to_netcdf('/g/data/g40/kc5856/access_panan_ssp126_SWMT/old_Pan01_SWMT_shelf/binned_heat_trans_pan01_M_10.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927825f-3cde-4716-bfa4-ed429610e1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-25.06] *",
   "language": "python",
   "name": "conda-env-analysis3-25.06-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
